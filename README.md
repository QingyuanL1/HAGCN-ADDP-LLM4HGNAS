#  Heterogeneous Attention-based Graph Convolutional Network for Solving Asymmetric Pickup and Delivery Problem
The HA-GCN model addresses Asymmetric Pickup and Delivery Problem (APDP) by integrating heterogeneous attention (HA) and graph convolutional networks (GCN), aiming to capture both node and edge features present in APDP instances. Training utilizes REINFORCE with rollout baseline, incorporating real-world geographical information.

## Paper
Our paper, **Heterogeneous Attention-based Graph Convolutional Network for Solving the Asymmetric Pickup and Delivery Problem**, is accepted at *IEEE Transactions on Automation Science and Engineering*.

lf our work is helpful for your research, please cite our paper:
```
@ARTICLE{10912442,
  author={Li, Jiayi and Wu, Guohua and Fan, Mingfeng and Cao, Zhiguang and Wang, Yalin},
  journal={IEEE Transactions on Automation Science and Engineering}, 
  title={Heterogeneous Attention-based Graph Convolutional Network for Solving Asymmetric Pickup and Delivery Problem}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  doi={10.1109/TASE.2025.3548141}}
```

## Data
To ascertain the applicability of the proposed method in express hubs or logistics centers scenarios, we collect a large amount of customer information as a pool for a specific region, i.e., Furong District, Changsha City, China. The customer pool (customer information) is crawled from **Amap**, which provides geographical coordinates and a distance matrix of 700 locations in the studied region, with each location corresponding to a potential customer. The coordinates are determined based on the WGS84 international standard coordinate system, and the values in the distance matrix are determined based on the shortest driving routes obtained from actual navigation. Notably, the crawled data exhibits a salient asymmetry in distances between two nodes. 

The experimental data used in this article has been made publicly available, where the geographic coordinates are in `excel/coordinates_700.xlsx` and the distance matrix is in `excel/distance_matrix_700.xlsx`.

## Dependencies
* Python>=3.6
* NumPy
* PyTorch>=1.1
* tensorboard_logger

## Usage
### Dataset
The customer location and distance data used for training and evaluating models are located in the `data` folder. These data will be utilized to randomly generate instances of different sizes throughout the training and evaluation processes.

### Training
To train APDP instances with 20 nodes and utilize rollout as the REINFORCE baseline, execute the following command:
```
python run.py --graph_size 20 --baseline rollout
```
Training is typically conducted across all available GPUs by default. To specify specific GPUs for use, set the environment variable `CUDA_VISIBLE_DEVICES`. The command is outlined below:
```
CUDA_VISIBLE_DEVICES=1,2 python run.py 
```
### Evaluation
Due to the large size of APDP models, the trained models used for evaluating can be downloaded from the following linkï¼š
* The model of APDP21: [pdp_20](https://drive.google.com/drive/folders/1gJJWrxah2GDpHft5ow8Ycmbpk7GRrJf9?usp=sharing)
* The model of APDP51: [pdp_50](https://drive.google.com/drive/folders/12GsFQRMgvLn_CJ5liEzUfQQ56I4jMa43?usp=sharing)
* The model of APDP101: [pdp_100](https://drive.google.com/drive/folders/19G7G99n1X6E-J-w1XsgPt7szyaMUWSEo?usp=sharing)
  
The model files can be downloaded into the `outputs` folder for convenient access during evaluation.

To evaluate a model, you can use `eval.py`. Foe example, to test the APDP21 model, the command is as follows:
```
python eval.py --model 'outputs/pdp_20/run_20230413T095145/epoch-49.pt' --decode_strategy greedy
```
To report the best of 1280 sampled solutions, you can execute the following command to test the APDP21 model:
```
python eval.py --model 'outputs/pdp_20/run_20230413T095145/epoch-49.pt' --decode_strategy sample --width 1280 --eval_batch_size 1
```
## Acknowledgements
Thanks to [attention-learn-to-route](https://github.com/wouterkool/attention-learn-to-route) for providing the initial codebase for the Attention Model (AM).

---

## ðŸš€ New Feature: LLM-driven Architecture Search (LLM4HGNAS)

This repository now supports **LLM-driven Graph Neural Network Architecture Search**, allowing GPT-4 to automatically design optimal encoder architectures for the APDP problem during reinforcement learning training.

### Key Features
- **Dynamic Search Space**: Explores combinations of `Attention`, `GCN`, `GAT`, and `MLP` operators for 7 different heterogeneous relations.
- **Performance Feedback**: Records training cost of each architecture and feeds "Top 5 Performing Architectures" back to the LLM to guide optimization (Gradient-descent like optimization).
- **Automated Exploration**: Automatically switches architectures every $K$ epochs.

### Quick Start
To enable NAS mode with GPT-4:

```bash
python run.py \
  --problem pdp \
  --graph_size 20 \
  --baseline rollout \
  --nas_enabled \
  --nas_arch_generator llm \
  --llm_model gpt-4 \
  --llm_api_key "YOUR_OPENAI_API_KEY" \
  --llm_base_url "https://api.openai.com/v1"
```

### NAS Arguments
| Argument | Default | Description |
| :--- | :--- | :--- |
| `--nas_enabled` | `False` | Enable dynamic architecture search. |
| `--nas_arch_generator` | `llm` | Choice between `llm` (GPT-4) or `random` (Random Search). |
| `--arch_switch_interval` | `10` | Frequency of architecture switching (every N epochs). |
| `--llm_model` | `gpt-4-0314` | The LLM model name to use. |
| `--llm_api_key` | `None` | Your OpenAI API Key (or set `OPENAI_API_KEY` env var). |

### Search History
The architecture search history and performance metrics are saved in `outputs/{problem}_{size}/{run_name}/nas_history.json`.
